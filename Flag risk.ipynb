{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2;\n",
       "                var nbb_unformatted_code = \"%load_ext nb_black\";\n",
       "                var nbb_formatted_code = \"%load_ext nb_black\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext nb_black"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 13;\n",
       "                var nbb_unformatted_code = \"# Loading all necessary libraries\\nimport numpy as np\\nimport pandas as pd\\nfrom os import path\\nfrom sklearn import preprocessing\\nfrom dateutil import parser\\nfrom collections import defaultdict\\nimport nltk\\nfrom nltk.corpus import stopwords\\nfrom nltk.tokenize import word_tokenize\\nimport re\\nimport spacy\\nimport matplotlib.pyplot as plt\\nimport matplotlib.backends.backend_pdf\\nimport random\\nimport json\\nfrom pprint import pprint\\nimport gc\\nfrom datetime import datetime\\nfrom datetime import timedelta\\nimport os\\nfrom sklearn.feature_extraction.text import CountVectorizer\\nimport seaborn as sns\\nfrom dateutil import parser\\nfrom datetime import timezone\\nimport pytz\\nfrom sklearn.decomposition import LatentDirichletAllocation as LDA\";\n",
       "                var nbb_formatted_code = \"# Loading all necessary libraries\\nimport numpy as np\\nimport pandas as pd\\nfrom os import path\\nfrom sklearn import preprocessing\\nfrom dateutil import parser\\nfrom collections import defaultdict\\nimport nltk\\nfrom nltk.corpus import stopwords\\nfrom nltk.tokenize import word_tokenize\\nimport re\\nimport spacy\\nimport matplotlib.pyplot as plt\\nimport matplotlib.backends.backend_pdf\\nimport random\\nimport json\\nfrom pprint import pprint\\nimport gc\\nfrom datetime import datetime\\nfrom datetime import timedelta\\nimport os\\nfrom sklearn.feature_extraction.text import CountVectorizer\\nimport seaborn as sns\\nfrom dateutil import parser\\nfrom datetime import timezone\\nimport pytz\\nfrom sklearn.decomposition import LatentDirichletAllocation as LDA\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Loading all necessary libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from os import path\n",
    "from sklearn import preprocessing\n",
    "from dateutil import parser\n",
    "from collections import defaultdict\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "import re\n",
    "import spacy\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.backends.backend_pdf\n",
    "import random\n",
    "import json\n",
    "from pprint import pprint\n",
    "import gc\n",
    "from datetime import datetime\n",
    "from datetime import timedelta\n",
    "import os\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import seaborn as sns\n",
    "from dateutil import parser\n",
    "from datetime import timezone\n",
    "import pytz\n",
    "from sklearn.decomposition import LatentDirichletAllocation as LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 14;\n",
       "                var nbb_unformatted_code = \"TYPE_PAGE_LIST = [\\\"politicians\\\"]\\nTYPE_SOCIAL_LIST = [\\\"facebook\\\"]  # [\\\"facebook\\\", \\\"instagram\\\"]\\nCOUNTRY_PAGE_LIST = [\\\"italy\\\"]\\n\\nDATA_PATH = \\\"data/\\\"\\nOUTPUT_PATH = \\\"output/\\\"\\n\\nCOLUMNS_TYPES_FB = {}\\nCOLUMNS_TYPES_IG = {}\";\n",
       "                var nbb_formatted_code = \"TYPE_PAGE_LIST = [\\\"politicians\\\"]\\nTYPE_SOCIAL_LIST = [\\\"facebook\\\"]  # [\\\"facebook\\\", \\\"instagram\\\"]\\nCOUNTRY_PAGE_LIST = [\\\"italy\\\"]\\n\\nDATA_PATH = \\\"data/\\\"\\nOUTPUT_PATH = \\\"output/\\\"\\n\\nCOLUMNS_TYPES_FB = {}\\nCOLUMNS_TYPES_IG = {}\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "TYPE_PAGE_LIST = [\"politicians\"]\n",
    "TYPE_SOCIAL_LIST = [\"facebook\"]  # [\"facebook\", \"instagram\"]\n",
    "COUNTRY_PAGE_LIST = [\"italy\"]\n",
    "\n",
    "DATA_PATH = \"data/\"\n",
    "OUTPUT_PATH = \"output/\"\n",
    "\n",
    "COLUMNS_TYPES_FB = {}\n",
    "COLUMNS_TYPES_IG = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'data/risk_keywords_month.json'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-2bba1d500672>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDATA_PATH\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"risk_keywords_month.json\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mjson_file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mrisk_words_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjson_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"risk_words\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'data/risk_keywords_month.json'"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 15;\n",
       "                var nbb_unformatted_code = \"with open(DATA_PATH + \\\"risk_keywords_month.json\\\") as json_file:\\n    risk_words_list = json.load(json_file)[\\\"risk_words\\\"]\";\n",
       "                var nbb_formatted_code = \"with open(DATA_PATH + \\\"risk_keywords_month.json\\\") as json_file:\\n    risk_words_list = json.load(json_file)[\\\"risk_words\\\"]\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "with open(DATA_PATH + \"risk_keywords_month.json\") as json_file:\n",
    "    risk_words_list = json.load(json_file)[\"risk_words\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "it_politicians_posts = pd.read_csv(\n",
    "    \"flag_risk_new/politicians_extended_posts.csv\", dtype={\"id\": str, \"text\": str}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "newspapers_posts = pd.read_csv(\n",
    "    \"flag_risk_new/newspapers_extended_posts.csv\", dtype={\"id\": str, \"text\": str}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "it_politicians_posts = it_politicians_posts[[\"id\", \"text\"]]\n",
    "# newspapers_posts = newspapers_posts[[\"id\", \"text\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>111183203772</td>\n",
       "      <td>🔴 Mentre gli italiani sono chiusi in casa, in ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>111173666592</td>\n",
       "      <td>In Germania i parlamentari del PD non potevano...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>111172721789</td>\n",
       "      <td>++ TUTTA ITALIA CHIUSA E BLINDATA AD ECCEZIONE...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>111165536109</td>\n",
       "      <td>#LAMPEDUSA: CONTINUA L’INVASIONE, SBARCATI ALT...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>111161470708</td>\n",
       "      <td>#LAMPEDUSA, MIGLIAIA DI MIGRANTI SBARCATI IN D...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1843</th>\n",
       "      <td>105204027795</td>\n",
       "      <td>MIGRANTI SCAPPANO DA #LAMPEDUSA A BORDO DI UN ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1844</th>\n",
       "      <td>105199138822</td>\n",
       "      <td>++ #SALVINI: \"LEGA DENUNCERÀ GOVERNO SE MIGRAN...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1845</th>\n",
       "      <td>105188887367</td>\n",
       "      <td>++ #SEAWATCH4: LA NAVE ONG VERSO PALERMO CON 3...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1846</th>\n",
       "      <td>105188887369</td>\n",
       "      <td>++ A PALERMO I 353 MIGRANTI DELLA #SEAWATCH4 ++</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1847</th>\n",
       "      <td>105185957016</td>\n",
       "      <td>‼️La Lega denuncerà il governo per FAVOREGGIAM...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1848 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                id                                               text\n",
       "0     111183203772  🔴 Mentre gli italiani sono chiusi in casa, in ...\n",
       "1     111173666592  In Germania i parlamentari del PD non potevano...\n",
       "2     111172721789  ++ TUTTA ITALIA CHIUSA E BLINDATA AD ECCEZIONE...\n",
       "3     111165536109  #LAMPEDUSA: CONTINUA L’INVASIONE, SBARCATI ALT...\n",
       "4     111161470708  #LAMPEDUSA, MIGLIAIA DI MIGRANTI SBARCATI IN D...\n",
       "...            ...                                                ...\n",
       "1843  105204027795  MIGRANTI SCAPPANO DA #LAMPEDUSA A BORDO DI UN ...\n",
       "1844  105199138822  ++ #SALVINI: \"LEGA DENUNCERÀ GOVERNO SE MIGRAN...\n",
       "1845  105188887367  ++ #SEAWATCH4: LA NAVE ONG VERSO PALERMO CON 3...\n",
       "1846  105188887369    ++ A PALERMO I 353 MIGRANTI DELLA #SEAWATCH4 ++\n",
       "1847  105185957016  ‼️La Lega denuncerà il governo per FAVOREGGIAM...\n",
       "\n",
       "[1848 rows x 2 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "it_politicians_posts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_risk(row):\n",
    "    for word in risk_words_list:\n",
    "        if word in row[\"text\"].lower():\n",
    "            return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# newspapers_posts[\"risk_flag\"] = newspapers_posts.apply(\n",
    "#    lambda row: check_risk(row), axis=1\n",
    "# )\n",
    "it_politicians_posts[\"risk_flag\"] = it_politicians_posts.apply(\n",
    "    lambda row: check_risk(row), axis=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "newspapers_posts.to_csv(\"flag_risk_new/politicians_posts_risk_flag.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
