{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext lab_black"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading all necessary libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from os import path\n",
    "from PIL import Image\n",
    "from wordcloud import WordCloud, STOPWORDS, ImageColorGenerator\n",
    "from sklearn import preprocessing\n",
    "from dateutil import parser\n",
    "from collections import defaultdict\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "import re\n",
    "import spacy\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.backends.backend_pdf\n",
    "import random\n",
    "import unidecode\n",
    "import emoji\n",
    "import json\n",
    "import gc\n",
    "import os\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import seaborn as sns\n",
    "from sklearn.decomposition import LatentDirichletAllocation as LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "sp = spacy.load(\"it_core_news_lg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Input Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TYPE_PAGE_LIST = [\"politicians\"]\n",
    "TYPE_SOCIAL_LIST = [\"facebook\"]  # [\"facebook\", \"instagram\"]\n",
    "COUNTRY_PAGE_LIST = [\"italy\"]\n",
    "\n",
    "DATA_PATH = \"data/\"\n",
    "OUTPUT_PATH = \"output/\"\n",
    "\n",
    "COLUMNS_TYPES_FB = {}\n",
    "COLUMNS_TYPES_IG = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MONTHS_2019 = {\"dec\": 12}\n",
    "MONTHS_2020 = {\n",
    "    \"jan\": 1,\n",
    "    \"feb\": 2,\n",
    "    \"mar\": 3,\n",
    "    \"apr\": 4,\n",
    "    \"may\": 5,\n",
    "    \"jun\": 6,\n",
    "    \"jul\": 7,\n",
    "    \"aug\": 8,\n",
    "}\n",
    "df_map = {}\n",
    "df_months_map = {\n",
    "    \"dec\": {},\n",
    "    \"jan\": {},\n",
    "    \"feb\": {},\n",
    "    \"mar\": {},\n",
    "    \"apr\": {},\n",
    "    \"may\": {},\n",
    "    \"jun\": {},\n",
    "    \"jul\": {},\n",
    "    \"aug\": {},\n",
    "}\n",
    "df_specific_party_map = {\n",
    "    \"dec\": {},\n",
    "    \"jan\": {},\n",
    "    \"feb\": {},\n",
    "    \"mar\": {},\n",
    "    \"apr\": {},\n",
    "    \"may\": {},\n",
    "    \"jun\": {},\n",
    "    \"jul\": {},\n",
    "    \"aug\": {},\n",
    "}\n",
    "df_pol_party_frequency_migration_map = {\n",
    "    \"dec\": {},\n",
    "    \"jan\": {},\n",
    "    \"feb\": {},\n",
    "    \"mar\": {},\n",
    "    \"apr\": {},\n",
    "    \"may\": {},\n",
    "    \"jun\": {},\n",
    "    \"jul\": {},\n",
    "    \"aug\": {},\n",
    "}\n",
    "df_pol_party_frequency_risk_map = {\n",
    "    \"dec\": {},\n",
    "    \"jan\": {},\n",
    "    \"feb\": {},\n",
    "    \"mar\": {},\n",
    "    \"apr\": {},\n",
    "    \"may\": {},\n",
    "    \"jun\": {},\n",
    "    \"jul\": {},\n",
    "    \"aug\": {},\n",
    "}\n",
    "df_pol_party_top_risk_map = {\n",
    "    \"dec\": {},\n",
    "    \"jan\": {},\n",
    "    \"feb\": {},\n",
    "    \"mar\": {},\n",
    "    \"apr\": {},\n",
    "    \"may\": {},\n",
    "    \"jun\": {},\n",
    "    \"jul\": {},\n",
    "    \"aug\": {},\n",
    "}\n",
    "lists_months_map = {\n",
    "    \"dec\": {},\n",
    "    \"jan\": {},\n",
    "    \"feb\": {},\n",
    "    \"mar\": {},\n",
    "    \"apr\": {},\n",
    "    \"may\": {},\n",
    "    \"jun\": {},\n",
    "    \"jul\": {},\n",
    "    \"aug\": {},\n",
    "}\n",
    "top_posts_map = {\n",
    "    \"dec\": {},\n",
    "    \"jan\": {},\n",
    "    \"feb\": {},\n",
    "    \"mar\": {},\n",
    "    \"apr\": {},\n",
    "    \"may\": {},\n",
    "    \"jun\": {},\n",
    "    \"jul\": {},\n",
    "    \"aug\": {},\n",
    "}\n",
    "risk_lists_months_map = {\n",
    "    \"dec\": {},\n",
    "    \"jan\": {},\n",
    "    \"feb\": {},\n",
    "    \"mar\": {},\n",
    "    \"apr\": {},\n",
    "    \"may\": {},\n",
    "    \"jun\": {},\n",
    "    \"jul\": {},\n",
    "    \"aug\": {},\n",
    "}\n",
    "risk_top_lists_months_map = {\n",
    "    \"dec\": {},\n",
    "    \"jan\": {},\n",
    "    \"feb\": {},\n",
    "    \"mar\": {},\n",
    "    \"apr\": {},\n",
    "    \"may\": {},\n",
    "    \"jun\": {},\n",
    "    \"jul\": {},\n",
    "    \"aug\": {},\n",
    "}\n",
    "figures = {\n",
    "    \"dec\": [],\n",
    "    \"jan\": [],\n",
    "    \"feb\": [],\n",
    "    \"mar\": [],\n",
    "    \"apr\": [],\n",
    "    \"may\": [],\n",
    "    \"jun\": [],\n",
    "    \"jul\": [],\n",
    "    \"aug\": [],\n",
    "}\n",
    "risk_figures = {\n",
    "    \"dec\": [],\n",
    "    \"jan\": [],\n",
    "    \"feb\": [],\n",
    "    \"mar\": [],\n",
    "    \"apr\": [],\n",
    "    \"may\": [],\n",
    "    \"jun\": [],\n",
    "    \"jul\": [],\n",
    "    \"aug\": [],\n",
    "}\n",
    "risk_top_figures = {\n",
    "    \"dec\": [],\n",
    "    \"jan\": [],\n",
    "    \"feb\": [],\n",
    "    \"mar\": [],\n",
    "    \"apr\": [],\n",
    "    \"may\": [],\n",
    "    \"jun\": [],\n",
    "    \"jul\": [],\n",
    "    \"aug\": [],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(DATA_PATH + \"politician_party_map.json\") as json_file:\n",
    "    politicians_party_map = json.load(json_file)\n",
    "\n",
    "with open(DATA_PATH + \"keywords_month.json\") as json_file:\n",
    "    keywords_month_map = json.load(json_file)\n",
    "\n",
    "with open(DATA_PATH + \"risk_keywords_month.json\") as json_file:\n",
    "    risk_keywords_month_map = json.load(json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for type_page in TYPE_PAGE_LIST:\n",
    "    for type_social in TYPE_SOCIAL_LIST:\n",
    "        for country_page in COUNTRY_PAGE_LIST:\n",
    "            name_df = \"_\".join((type_page, type_social, country_page))\n",
    "            df_map[name_df] = pd.read_csv(DATA_PATH + name_df + \".csv\", header=0,)\n",
    "            df_map[name_df][\"Created\"] = df_map[name_df][\"Created\"].apply(\n",
    "                lambda x: parser.parse(x)\n",
    "            )\n",
    "            if type_social == \"instagram\":\n",
    "                df_map[name_df][\"Description\"] = df_map[name_df][\"Description\"].fillna(\n",
    "                    value=\"\"\n",
    "                )\n",
    "            else:\n",
    "                df_map[name_df][\"Message\"] = df_map[name_df][\"Message\"].fillna(value=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_map[\"politicians_facebook_italy\"].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create DFs Map per Month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name_df, df in df_map.items():\n",
    "    df_months_map[list(MONTHS_2019.keys())[0]][name_df] = df_map[name_df][\n",
    "        (df_map[name_df][\"Created\"] >= \"2019-12-01\")\n",
    "        & (df_map[name_df][\"Created\"] < \"2020-01-01\")\n",
    "    ].copy()\n",
    "\n",
    "for name_df, df in df_map.items():\n",
    "    for month in MONTHS_2020.keys():\n",
    "        df_months_map[month][name_df] = df_map[name_df][\n",
    "            (df_map[name_df][\"Created\"] >= \"2020-{}-01\".format(MONTHS_2020[month]))\n",
    "            & (df_map[name_df][\"Created\"] < \"2020-{}-01\".format(MONTHS_2020[month] + 1))\n",
    "        ].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del df_map\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_stopwords = sp.Defaults.stop_words\n",
    "with open(\"stopwords_italian.json\") as json_file:\n",
    "    italian_stopwords = json.load(json_file)\n",
    "all_stopwords |= set(italian_stopwords[\"stopwords\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_emoji(text):\n",
    "    return emoji.get_emoji_regexp().sub(u\"\", text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    text = remove_emoji(text)\n",
    "    # text = unidecode.unidecode(text)\n",
    "    text = text.lower()\n",
    "    text = text.strip()\n",
    "    text = re.sub(\"#\\S+:\", \"\", text)\n",
    "    text = re.sub(\"# \\S+ :\", \"\", text)\n",
    "    text = re.sub(\"#\\S+ :\", \"\", text)\n",
    "    text = re.sub(\"# \\S+:\", \"\", text)\n",
    "    text = re.sub(\"#\\S+\", \"\", text)\n",
    "    text = re.sub(\"legaonline.it\\S+\", \"\", text)\n",
    "    text = re.sub(\"[,\\.!?#]\", \"\", text)\n",
    "    text = re.sub(\"\\s+\", \" \", text)\n",
    "    text = (\n",
    "        text.replace(\"http\", \"\")\n",
    "        .replace(\"www\", \"\")\n",
    "        .replace(\"shortener\", \"\")\n",
    "        .replace(\"ref\", \"\")\n",
    "        .replace(\"matteo salvini\", \"salvini\")\n",
    "        .replace(\"user\", \"\")\n",
    "        .replace(\"legaonline.it/iostoconsalvini\", \"\")\n",
    "    )\n",
    "    text = re.sub(\"\\s+\", \" \", text)\n",
    "    # stop_words = set(stopwords.words(\"italian\"))\n",
    "    text_tokens = word_tokenize(text)\n",
    "    tokens_without_sw = [word for word in text_tokens if not word in all_stopwords]\n",
    "\n",
    "    res = \" \".join(tokens_without_sw)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create map divided by couple politician + party and by month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for month, df_map_month in df_months_map.items():\n",
    "    for df_name, df_data in df_map_month.items():\n",
    "        for pol, party in politicians_party_map.items():\n",
    "            if len(party) > 0:\n",
    "                complete_name = (\n",
    "                    pol.lower().replace(\" - \", \" \").replace(\" \", \"_\")\n",
    "                    + \"__\"\n",
    "                    + party.lower().replace(\" - \", \" \").replace(\" \", \"_\")\n",
    "                )\n",
    "                df_specific_party_map[month][complete_name] = df_data.loc[\n",
    "                    df_data[\"Page Name\"].isin([pol, party])\n",
    "                ].copy()\n",
    "            else:\n",
    "                complete_name = pol.lower().replace(\" - \", \" \").replace(\" \", \"_\")\n",
    "                df_specific_party_map[month][complete_name] = df_data.loc[\n",
    "                    df_data[\"Page Name\"].isin([pol])\n",
    "                ].copy()\n",
    "            df_specific_party_map[month][complete_name][\n",
    "                \"Message\"\n",
    "            ] = df_specific_party_map[month][complete_name][\"Message\"].apply(\n",
    "                lambda x: clean_text(x)\n",
    "            )\n",
    "            df_specific_party_map[month][complete_name] = df_specific_party_map[month][\n",
    "                complete_name\n",
    "            ].reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PLOT OF: Frequency of migration related posts per politician + party (together as one) throughout time "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def avg_engagement(df_):\n",
    "    engagements = []\n",
    "    interactions_list = []\n",
    "    for index, row in df_.iterrows():\n",
    "        followers = row[\"Likes at Posting\"]\n",
    "        interactions = (\n",
    "            row[\"Likes\"]\n",
    "            + row[\"Comments\"]\n",
    "            + row[\"Shares\"]\n",
    "            + row[\"Love\"]\n",
    "            + row[\"Wow\"]\n",
    "            + row[\"Haha\"]\n",
    "            + row[\"Sad\"]\n",
    "            + row[\"Angry\"]\n",
    "            + row[\"Care\"]\n",
    "        )\n",
    "        # print(row)\n",
    "        # print(followers)\n",
    "        # print(interactions)\n",
    "        engagements.append((interactions / followers) * 100)\n",
    "        interactions_list.append(interactions)\n",
    "        mean_engagement = sum(engagements) / len(engagements)\n",
    "        mean_interactions = sum(interactions_list) / len(interactions_list)\n",
    "    return round(mean_engagement, 2), round(mean_interactions, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for month, df_map_month in df_specific_party_map.items():\n",
    "    lists_months_map[month] = {\n",
    "        \"page_names\": [],\n",
    "        \"freq\": [],\n",
    "        \"avg_engagement\": [],\n",
    "        \"avg_interactions\": [],\n",
    "    }\n",
    "    for df_name, df_data in df_map_month.items():\n",
    "        words = \"|\".join(w for w in keywords_month_map[month])\n",
    "        migration_posts = (\n",
    "            df_data[df_data[\"Message\"].str.contains(words)].copy().reset_index()\n",
    "        )\n",
    "        freq = len(migration_posts)\n",
    "        # print(month,df_name,freq)\n",
    "        if freq > 0:\n",
    "            mean_engagement, mean_interactions = avg_engagement(migration_posts)\n",
    "        else:\n",
    "            mean_engagement = 0\n",
    "            mean_interactions = 0\n",
    "        df_pol_party_frequency_migration_map[month][df_name] = {\n",
    "            \"freq\": freq,\n",
    "            \"avg_engagement\": mean_engagement,\n",
    "            \"avg_interactions\": mean_interactions,\n",
    "        }\n",
    "        lists_months_map[month][\"page_names\"].append(df_name)\n",
    "        lists_months_map[month][\"freq\"].append(freq)\n",
    "        lists_months_map[month][\"avg_engagement\"].append(mean_engagement)\n",
    "        lists_months_map[month][\"avg_interactions\"].append(mean_interactions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_pol_party_frequency_migration_map[\"mar\"])\n",
    "print(df_pol_party_frequency_migration_map[\"dec\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalization parameters\n",
    "normalize_min = 0.1\n",
    "normalize_max = 1\n",
    "for month, lists_map in lists_months_map.items():\n",
    "    pages_names = lists_map[\"page_names\"]\n",
    "    engagements = lists_map[\"avg_engagement\"]\n",
    "    freq = lists_map[\"freq\"]\n",
    "    mean_interactions = lists_map[\"avg_interactions\"]\n",
    "    # Normalize\n",
    "    freq = preprocessing.minmax_scale(\n",
    "        freq, feature_range=(normalize_min, normalize_max)\n",
    "    )\n",
    "    engagements = preprocessing.minmax_scale(\n",
    "        engagements, feature_range=(normalize_min, normalize_max)\n",
    "    )\n",
    "    mean_interactions = preprocessing.minmax_scale(\n",
    "        mean_interactions, feature_range=(normalize_min, normalize_max)\n",
    "    )\n",
    "\n",
    "    df = pd.DataFrame(\n",
    "        {\n",
    "            \"avg engagement\": engagements,\n",
    "            \"posts containing migration keywords\": freq,\n",
    "            \"avg interactions\": mean_interactions,\n",
    "        },\n",
    "        index=[p.replace(\"__\", \" + \").replace(\"_\", \" \") for p in pages_names],\n",
    "    )\n",
    "    if len(df) > 0:\n",
    "        ax = df.sort_values(\n",
    "            \"posts containing migration keywords\", ascending=False\n",
    "        ).plot(\n",
    "            kind=\"bar\",\n",
    "            title=\"Frequency of migration related posts per politician + party per month - {}\".format(\n",
    "                month\n",
    "            ),\n",
    "            rot=90,\n",
    "        )\n",
    "        figures[month].append(ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate PDFs of migration post by month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for month, plots in figures.items():\n",
    "    if month == \"dec\":\n",
    "        name_file = OUTPUT_PATH + \"frequency_migration_by_month/2019_{}.pdf\".format(\n",
    "            month\n",
    "        )\n",
    "    else:\n",
    "        name_file = OUTPUT_PATH + \"frequency_migration_by_month/2020_{}.pdf\".format(\n",
    "            month\n",
    "        )\n",
    "    pdf = matplotlib.backends.backend_pdf.PdfPages(name_file)\n",
    "    for fig in plots:  ## will open an empty extra figure :(\n",
    "        fig = fig.get_figure()\n",
    "        # print(type(fig))\n",
    "        pdf.savefig(fig, bbox_inches=\"tight\")\n",
    "    pdf.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PLOT OF: Risk and threat narrative (keyword list) frequency over time per politician + party"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "risk_words = \"|\".join(w for w in risk_keywords_month_map[\"risk_words\"])\n",
    "for month, df_map_month in df_specific_party_map.items():\n",
    "    risk_lists_months_map[month] = {\n",
    "        \"page_names\": [],\n",
    "        \"freq\": [],\n",
    "        \"avg_engagement\": [],\n",
    "        \"avg_interactions\": [],\n",
    "    }\n",
    "    for df_name, df_data in df_map_month.items():\n",
    "        risk_posts = (\n",
    "            df_data[df_data[\"Message\"].str.contains(risk_words)].copy().reset_index()\n",
    "        )\n",
    "        freq = len(risk_posts)\n",
    "        # print(month,df_name,freq)\n",
    "        if freq > 0:\n",
    "            mean_engagement, mean_interactions = avg_engagement(risk_posts)\n",
    "        else:\n",
    "            mean_engagement = 0\n",
    "            mean_interactions = 0\n",
    "        df_pol_party_frequency_risk_map[month][df_name] = {\n",
    "            \"freq\": freq,\n",
    "            \"avg_engagement\": mean_engagement,\n",
    "            \"avg_interactions\": mean_interactions,\n",
    "        }\n",
    "        risk_lists_months_map[month][\"page_names\"].append(df_name)\n",
    "        risk_lists_months_map[month][\"freq\"].append(freq)\n",
    "        risk_lists_months_map[month][\"avg_engagement\"].append(mean_engagement)\n",
    "        risk_lists_months_map[month][\"avg_interactions\"].append(mean_interactions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalization parameters\n",
    "normalize_min = 0.1\n",
    "normalize_max = 1\n",
    "for month, lists_map in risk_lists_months_map.items():\n",
    "    pages_names = lists_map[\"page_names\"]\n",
    "    engagements = lists_map[\"avg_engagement\"]\n",
    "    freq = lists_map[\"freq\"]\n",
    "    mean_interactions = lists_map[\"avg_interactions\"]\n",
    "    # Normalize\n",
    "    freq = preprocessing.minmax_scale(\n",
    "        freq, feature_range=(normalize_min, normalize_max)\n",
    "    )\n",
    "    engagements = preprocessing.minmax_scale(\n",
    "        engagements, feature_range=(normalize_min, normalize_max)\n",
    "    )\n",
    "    mean_interactions = preprocessing.minmax_scale(\n",
    "        mean_interactions, feature_range=(normalize_min, normalize_max)\n",
    "    )\n",
    "\n",
    "    df = pd.DataFrame(\n",
    "        {\n",
    "            \"avg engagement\": engagements,\n",
    "            \"posts containing risk keywords\": freq,\n",
    "            \"avg interactions\": mean_interactions,\n",
    "        },\n",
    "        index=[p.replace(\"__\", \" + \").replace(\"_\", \" \") for p in pages_names],\n",
    "    )\n",
    "    if len(df) > 0:\n",
    "        ax = df.sort_values(\n",
    "            \"posts containing risk keywords\", ascending=False\n",
    "        ).plot(\n",
    "            kind=\"bar\",\n",
    "            title=\"Frequency of risk related posts per politician + party per month - {}\".format(\n",
    "                month\n",
    "            ),\n",
    "            rot=90,\n",
    "        )\n",
    "        risk_figures[month].append(ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate PDFs of risk post by month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for month, plots in risk_figures.items():\n",
    "    if month == \"dec\":\n",
    "        name_file = OUTPUT_PATH + \"frequency_risk_by_month/2019_{}.pdf\".format(month)\n",
    "    else:\n",
    "        name_file = OUTPUT_PATH + \"frequency_risk_by_month/2020_{}.pdf\".format(month)\n",
    "    pdf = matplotlib.backends.backend_pdf.PdfPages(name_file)\n",
    "    for fig in plots:  ## will open an empty extra figure :(\n",
    "        fig = fig.get_figure()\n",
    "        # print(type(fig))\n",
    "        pdf.savefig(fig, bbox_inches=\"tight\")\n",
    "    pdf.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PLOT OF -using only the top ten (engagement) posts from Italian politicians on fb and Instagram as a corpus/subset of data-:  risk and threat narrative frequency in the TOP TEN (most liked/shared etc.) posts, by politicians"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_best_posts(df, social_type):\n",
    "    if social_type == \"instagram\":\n",
    "        df[\"interactions\"] = df[\"Likes\"] + df[\"Comments\"]\n",
    "        df = df.sort_values(\n",
    "            by=[\"interactions\", \"Overperforming Score\"], ascending=False\n",
    "        ).iloc[0:10]\n",
    "    else:\n",
    "        df[\"interactions\"] = (\n",
    "            df[\"Likes\"]\n",
    "            + df[\"Comments\"]\n",
    "            + df[\"Shares\"]\n",
    "            + df[\"Love\"]\n",
    "            + df[\"Haha\"]\n",
    "            + df[\"Wow\"]\n",
    "            + df[\"Sad\"]\n",
    "            + df[\"Care\"]\n",
    "            + df[\"Angry\"]\n",
    "        )\n",
    "        df = df.sort_values(\n",
    "            by=[\"interactions\", \"Overperforming Score\"], ascending=False\n",
    "        ).iloc[0:10]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for month, df_map_month in df_specific_party_map.items():\n",
    "    for df_name, df_data in df_map_month.items():\n",
    "        # social_type = df_name.split(\"_\")[1]\n",
    "        social_type = \"facebook\"\n",
    "        df = get_best_posts(df_data.copy(), social_type)\n",
    "        top_posts_map[month][df_name] = df.reset_index().drop(\n",
    "            columns=[\"level_0\", \"index\"]\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "risk_words = \"|\".join(w for w in risk_keywords_month_map[\"risk_words\"])\n",
    "for month, df_map_month in top_posts_map.items():\n",
    "    risk_top_lists_months_map[month] = {\n",
    "        \"page_names\": [],\n",
    "        \"freq\": [],\n",
    "        \"avg_engagement\": [],\n",
    "        \"avg_interactions\": [],\n",
    "    }\n",
    "    for df_name, df_data in df_map_month.items():\n",
    "        risk_top_posts = (\n",
    "            df_data[df_data[\"Message\"].str.contains(risk_words)].copy().reset_index()\n",
    "        )\n",
    "        freq = len(risk_posts)\n",
    "        # print(month,df_name,freq)\n",
    "        if freq > 0:\n",
    "            mean_engagement, mean_interactions = avg_engagement(risk_top_posts)\n",
    "        else:\n",
    "            mean_engagement = 0\n",
    "            mean_interactions = 0\n",
    "        df_pol_party_top_risk_map[month][df_name] = {\n",
    "            \"freq\": freq,\n",
    "            \"avg_engagement\": mean_engagement,\n",
    "            \"avg_interactions\": mean_interactions,\n",
    "        }\n",
    "        risk_top_lists_months_map[month][\"page_names\"].append(df_name)\n",
    "        risk_top_lists_months_map[month][\"freq\"].append(freq)\n",
    "        risk_top_lists_months_map[month][\"avg_engagement\"].append(mean_engagement)\n",
    "        risk_top_lists_months_map[month][\"avg_interactions\"].append(mean_interactions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalization parameters\n",
    "normalize_min = 0.1\n",
    "normalize_max = 1\n",
    "for month, lists_map in risk_top_lists_months_map.items():\n",
    "    pages_names = lists_map[\"page_names\"]\n",
    "    engagements = lists_map[\"avg_engagement\"]\n",
    "    freq = lists_map[\"freq\"]\n",
    "    mean_interactions = lists_map[\"avg_interactions\"]\n",
    "    # Normalize\n",
    "    freq = preprocessing.minmax_scale(\n",
    "        freq, feature_range=(normalize_min, normalize_max)\n",
    "    )\n",
    "    engagements = preprocessing.minmax_scale(\n",
    "        engagements, feature_range=(normalize_min, normalize_max)\n",
    "    )\n",
    "    mean_interactions = preprocessing.minmax_scale(\n",
    "        mean_interactions, feature_range=(normalize_min, normalize_max)\n",
    "    )\n",
    "\n",
    "    df = pd.DataFrame(\n",
    "        {\n",
    "            \"avg engagement\": engagements,\n",
    "            \"posts containing risk keywords\": freq,\n",
    "            \"avg interactions\": mean_interactions,\n",
    "        },\n",
    "        index=[p.replace(\"__\", \" + \").replace(\"_\", \" \") for p in pages_names],\n",
    "    )\n",
    "    if len(df) > 0:\n",
    "        ax = df.sort_values(\n",
    "            \"posts containing risk keywords\", ascending=False\n",
    "        ).plot(\n",
    "            kind=\"bar\",\n",
    "            title=\"Frequency of risk related posts (among top posts) per politician + party per month - {}\".format(\n",
    "                month\n",
    "            ),\n",
    "            rot=90,\n",
    "        )\n",
    "        risk_top_figures[month].append(ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate PDFs of risk post by month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for month, plots in risk_top_figures.items():\n",
    "    if month == \"dec\":\n",
    "        name_file = OUTPUT_PATH + \"frequency_risk_topten/2019_{}.pdf\".format(month)\n",
    "    else:\n",
    "        name_file = OUTPUT_PATH + \"frequency_risk_topten/2020_{}.pdf\".format(month)\n",
    "    pdf = matplotlib.backends.backend_pdf.PdfPages(name_file)\n",
    "    for fig in plots:  ## will open an empty extra figure :(\n",
    "        fig = fig.get_figure()\n",
    "        # print(type(fig))\n",
    "        pdf.savefig(fig, bbox_inches=\"tight\")\n",
    "    pdf.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ricerca",
   "language": "python",
   "name": "ricerca"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
